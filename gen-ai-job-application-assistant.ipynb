{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sreejab22/gen-ai-job-application-assistant-capstone?scriptVersionId=234136311\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"d7f9acfd","metadata":{"papermill":{"duration":0.003282,"end_time":"2025-04-15T22:10:31.316976","exception":false,"start_time":"2025-04-15T22:10:31.313694","status":"completed"},"tags":[]},"source":["# ðŸ¤– Gen AI Job Application Assistant (Capstone Project)\n","\n","This notebook demonstrates a Generative AI-powered assistant that:\n","- Matches resumes to job descriptions\n","- Generates structured JSON with job match info\n","- Creates personalized cover letters\n","\n","Built using **Google Gemini Pro**, it showcases three core GenAI capabilities:\n","1. Retrieval-Augmented Generation\n","2. Structured Output (JSON)\n","3. Agent-style Task Automation\n","4. Few-shot Prompting\n","5. Grounding\n","6. Long Context Handling"]},{"cell_type":"markdown","id":"756bda98","metadata":{"papermill":{"duration":0.00172,"end_time":"2025-04-15T22:10:31.320905","exception":false,"start_time":"2025-04-15T22:10:31.319185","status":"completed"},"tags":[]},"source":["## ðŸ”— Project Links\n","\n","- ðŸ“– **Blog Post**: [Read it on Medium](https://medium.com/@bethusreeja/automating-job-applications-with-gen-ai-my-google-capstone-project-using-gemini-pro-701e31745a9e)\n","- ðŸŽ¥ **Demo Video**: [Watch on YouTube](https://www.youtube.com/watch?v=olx944mnz5U)\n","\n","This project was created as part of the **Google Gen AI Intensive Capstone 2025**. It showcases how Generative AI can automate job applications using Google Gemini Pro.\n"]},{"cell_type":"markdown","id":"1b1d78ca","metadata":{"papermill":{"duration":0.001727,"end_time":"2025-04-15T22:10:31.324492","exception":false,"start_time":"2025-04-15T22:10:31.322765","status":"completed"},"tags":[]},"source":["## ðŸ‘¥ Authors\n","\n","Sreeja Bethu â€” Lead Developer, Prompt Engineer, and Workflow Architect\n","  ðŸ”— [LinkedIn](https://www.linkedin.com/in/sreejabethu/) | ðŸ§  [Kaggle](https://www.kaggle.com/sreejab22)  "]},{"cell_type":"markdown","id":"0156e803","metadata":{"papermill":{"duration":0.001753,"end_time":"2025-04-15T22:10:31.328148","exception":false,"start_time":"2025-04-15T22:10:31.326395","status":"completed"},"tags":[]},"source":["## ðŸ“Œ Use Case: Automating Tailored Job Applications\n","\n","Job seekers spend hours tailoring resumes, writing cover letters, and organizing job submissions.\n","\n","**This assistant automates that workflow**:\n","- Compares resumes with job descriptions\n","- Calculates match score and generates resume bullets\n","- Produces structured JSON and a personalized cover letter"]},{"cell_type":"markdown","id":"68fd4907","metadata":{"papermill":{"duration":0.001704,"end_time":"2025-04-15T22:10:31.331712","exception":false,"start_time":"2025-04-15T22:10:31.330008","status":"completed"},"tags":[]},"source":["## ðŸ¤– Gen AI Capabilities Used\n","**1. Retrieval-Augmented Generation** â€“ uses job+resume as context for smart prompt output\n","\n","**2. Structured Output (JSON)** â€“ formats results for use in job trackers or automation tools\n","\n","**3. Agent-style Automation** â€“ chains together multiple LLM tasks (match â†’ bullet points â†’ cover letter)\n","\n","**4. Few-shot Prompting** â€“ Leverages example-driven prompts to guide Gemini in producing high-quality, personalized content.\n","\n","**5. Grounding** â€“ Ensures responses are based on actual input from resumes and job descriptions.\n","\n","**6. Long Context Handling** â€“ Processes entire resumes and lengthy job descriptions within a single prompt efficiently."]},{"cell_type":"code","execution_count":1,"id":"a8e5900e","metadata":{"execution":{"iopub.execute_input":"2025-04-15T22:10:31.33675Z","iopub.status.busy":"2025-04-15T22:10:31.336417Z","iopub.status.idle":"2025-04-15T22:10:37.834417Z","shell.execute_reply":"2025-04-15T22:10:37.833405Z"},"papermill":{"duration":6.502968,"end_time":"2025-04-15T22:10:37.836535","exception":false,"start_time":"2025-04-15T22:10:31.333567","status":"completed"},"tags":[]},"outputs":[],"source":["# âœ… Install and configure Gemini API\n","!pip install -q google-generativeai\n","import google.generativeai as genai\n","\n","GOOGLE_API_KEY = 'AIzaSyDaLYUNjEV6fB4G5kV9nhJ3pKq6zTTH6F8' \n","genai.configure(api_key=GOOGLE_API_KEY)\n","model = genai.GenerativeModel(model_name='models/gemini-2.0-flash')  # Check model name via genai.list_models()"]},{"cell_type":"code","execution_count":2,"id":"9aba5393","metadata":{"execution":{"iopub.execute_input":"2025-04-15T22:10:37.843875Z","iopub.status.busy":"2025-04-15T22:10:37.843311Z","iopub.status.idle":"2025-04-15T22:10:37.848097Z","shell.execute_reply":"2025-04-15T22:10:37.846951Z"},"papermill":{"duration":0.009904,"end_time":"2025-04-15T22:10:37.84978","exception":false,"start_time":"2025-04-15T22:10:37.839876","status":"completed"},"tags":[]},"outputs":[],"source":["# âœ… Provide sample job description and resume\n","job_description = '''We are hiring a Data Engineer with expertise in Snowflake, SQL, dbt, and cloud platforms like AWS or Azure. The role requires building and maintaining scalable data pipelines, ensuring data quality, and working with stakeholders.''' \n","\n","resume = '''Sreeja Bethu â€“ 7+ years of experience in data engineering, SQL, Snowflake, AWS, Azure, and ETL workflows. Strong in stakeholder collaboration, data modeling, and automation.'''"]},{"cell_type":"code","execution_count":3,"id":"b074e188","metadata":{"execution":{"iopub.execute_input":"2025-04-15T22:10:37.855897Z","iopub.status.busy":"2025-04-15T22:10:37.85548Z","iopub.status.idle":"2025-04-15T22:10:40.765426Z","shell.execute_reply":"2025-04-15T22:10:40.764213Z"},"papermill":{"duration":2.914335,"end_time":"2025-04-15T22:10:40.76683","exception":false,"start_time":"2025-04-15T22:10:37.852495","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Okay, let's analyze the resume and job description.\n","\n","**1. Matching Skills:**\n","\n","*   **Snowflake:** Both the job description and resume explicitly mention Snowflake.\n","*   **SQL:** Both explicitly mention SQL.\n","*   **AWS/Azure (Cloud Platforms):** The job description asks for experience with AWS or Azure, and the resume lists both.\n","*   **Stakeholder Collaboration:** The job description mentions \"working with stakeholders,\" and the resume mentions \"stakeholder collaboration.\"\n","*   **Data Engineering:** Both the job description and the resume mention data engineering.\n","\n","**2. Match Score (0-10):**\n","\n","Based on the information provided, I'd give this resume a **9/10**.\n","\n","*   It hits almost all the key technical skills.\n","*   It also touches on the soft skill of stakeholder collaboration.\n","*   The 7+ years of experience further strengthen the match.\n","*   The only missing explicit mention is dbt, which is a relatively specific tool.\n","\n","**3. Suggested Bullet Points to Add to the Resume:**\n","\n","To further improve the resume's alignment with the job description, I would suggest adding bullet points that showcase Sreeja's ability to build data pipelines and maintain data quality. Here are two suggestions:\n","\n","*   \"Developed and maintained scalable data pipelines on AWS utilizing services such as S3, Lambda, and Glue, resulting in a 30% reduction in data processing time.\" (This emphasizes pipeline building and AWS experience).\n","*   \"Implemented data quality checks and validation processes using SQL and Python, ensuring data accuracy and consistency across various data sources.\" (This highlights data quality and includes a mention of Python, which can be inferred as an asset from the need to automate tasks).\n","\n","These additions would address the explicit requirements of building data pipelines and ensuring data quality from the job description, further strengthening the resume's effectiveness. While dbt is missing, mentioning relevant services would increase the probability of selection.\n","\n"]}],"source":["# âœ… Step 1: Score match and suggest bullet points\n","prompt = f'''\n","Compare the resume and job description below.\n","\n","1. List matching skills\n","2. Provide a match score (0â€“10)\n","3. Suggest 2 bullet points to add to the resume\n","\n","Job Description:\n","{job_description}\n","\n","Resume:\n","{resume}\n","'''\n","\n","response = model.generate_content(prompt)\n","print(response.text)"]},{"cell_type":"code","execution_count":4,"id":"ba5f0ad6","metadata":{"execution":{"iopub.execute_input":"2025-04-15T22:10:40.772684Z","iopub.status.busy":"2025-04-15T22:10:40.772404Z","iopub.status.idle":"2025-04-15T22:10:42.619895Z","shell.execute_reply":"2025-04-15T22:10:42.618614Z"},"papermill":{"duration":1.851762,"end_time":"2025-04-15T22:10:42.621226","exception":false,"start_time":"2025-04-15T22:10:40.769464","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["```json\n","{\n","  \"job_title\": \"Data Engineer\",\n","  \"company\": \"Unknown (from provided information)\",\n","  \"match_score\": 90,\n","  \"resume_bullets\": [\n","    \"7+ years of experience in data engineering\",\n","    \"Proficient in SQL\",\n","    \"Expertise in Snowflake\",\n","    \"Experience with AWS and Azure cloud platforms\",\n","    \"Knowledge of ETL workflows\",\n","    \"Strong in stakeholder collaboration\",\n","    \"Proficient in data modeling\",\n","    \"Experience with automation\"\n","  ],\n","  \"custom_cover_letter\": \"Dear Hiring Manager,\\n\\nI am writing to express my keen interest in the Data Engineer position at your company. With over 7 years of experience in data engineering and a strong foundation in SQL, Snowflake, AWS, and Azure, I am confident I possess the skills and experience necessary to excel in this role.\\n\\nMy resume highlights my expertise in building and maintaining data pipelines, ensuring data quality, and collaborating with stakeholders. I have a proven track record of success in data modeling, ETL workflows, and automation. I am particularly excited about the opportunity to leverage my Snowflake expertise to contribute to your data initiatives.\\n\\nI am eager to learn more about this opportunity and discuss how my skills and experience can benefit your team. Thank you for your time and consideration.\\n\\nSincerely,\\nSreeja Bethu\"\n","}\n","```\n"]}],"source":["# âœ… Step 2: Generate structured JSON output\n","json_prompt = f'''\n","Generate a JSON object with:\n","- job_title\n","- company\n","- match_score\n","- resume_bullets\n","- custom_cover_letter\n","\n","Use the job description and resume.\n","\n","Job:\n","{job_description}\n","Resume:\n","{resume}\n","'''\n","\n","response = model.generate_content(json_prompt)\n","print(response.text)"]},{"cell_type":"markdown","id":"93000bc4","metadata":{"papermill":{"duration":0.001978,"end_time":"2025-04-15T22:10:42.625923","exception":false,"start_time":"2025-04-15T22:10:42.623945","status":"completed"},"tags":[]},"source":["## âœ… Conclusion\n","\n","This GenAI Assistant automates a previously manual process:\n","- Smartly analyzes job fit\n","- Structures results for tracking\n","- Writes personalized cover letters\n","\n","**Extensions:**\n","- Job scraping (LinkedIn, Indeed)\n","- Google Sheets job tracker\n","- Gmail API for automated follow-ups\n","\n","ðŸŽ¯ A perfect example of real-world GenAI in career automation."]},{"cell_type":"markdown","id":"41afc855","metadata":{"papermill":{"duration":0.001946,"end_time":"2025-04-15T22:10:42.630007","exception":false,"start_time":"2025-04-15T22:10:42.628061","status":"completed"},"tags":[]},"source":["import pandas as pd\n","\n","# Sample structure based on your Gemini output\n","submission_data = [\n","    {\n","        \"id\": \"001\",\n","        \"job_match_score\": 87,\n","        \"matched_title\": \"Data Engineer\",\n","        \"summary\": \"Strong match based on technical skills and healthcare experience\"\n","    }\n","]\n","\n","# Create DataFrame\n","df = pd.DataFrame(submission_data)\n","\n","# Save to CSV (required format for competition)\n","df.to_csv(\"submission.csv\", index=False)\n","\n","print(\"âœ… submission.csv has been created and saved.\")\n"]},{"cell_type":"markdown","id":"41c476e0","metadata":{"papermill":{"duration":0.0019,"end_time":"2025-04-15T22:10:42.6341","exception":false,"start_time":"2025-04-15T22:10:42.6322","status":"completed"},"tags":[]},"source":["!kaggle competitions submit -c gen-ai-intensive-course-capstone-2025q1 -f submission.csv -m \"Capstone demo\""]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97258,"sourceType":"competition"},{"datasetId":7156473,"sourceId":11426544,"sourceType":"datasetVersion"},{"datasetId":7156481,"sourceId":11426555,"sourceType":"datasetVersion"},{"datasetId":7156570,"sourceId":11426705,"sourceType":"datasetVersion"},{"sourceId":234130194,"sourceType":"kernelVersion"},{"isSourceIdPinned":true,"modelId":305232,"modelInstanceId":284386,"sourceId":340073,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30918,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":17.015852,"end_time":"2025-04-15T22:10:45.304746","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-15T22:10:28.288894","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}